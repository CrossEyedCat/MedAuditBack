# Руководство по оптимизации производительности

## Реализованные оптимизации

### 1. Кеширование данных

#### Кеширование списков отчетов
- **Место**: `app/api/v1/endpoints/reports.py`
- **TTL**: 5 минут (300 секунд)
- **Ключ**: `reports:user:{user_id}:page:{page}:size:{size}:status:{status}`
- **Условия**: Кешируются только стандартные запросы без сложных фильтров

#### Кеширование метаданных документов
- **Место**: `app/api/v1/endpoints/documents.py`
- **TTL**: 10 минут (600 секунд) для отдельных документов, 5 минут для списков
- **Ключи**:
  - `document:{document_id}:user:{user_id}` - отдельный документ
  - `documents:user:{user_id}:page:{page}:size:{size}:status:{status}:mime:{mime_type}` - список

#### Кеширование PDF отчетов
- **Место**: `app/api/v1/endpoints/reports.py`
- **TTL**: 24 часа (86400 секунд)
- **Ключ**: `pdf_report:{report_id}`
- **Формат**: Base64-encoded PDF содержимое

#### Инвалидация кеша
- При удалении документа инвалидируются все связанные кеши
- При создании документа инвалидируется кеш списков
- Endpoint для ручной инвалидации: `POST /api/v1/reports/{report_id}/invalidate-cache`

### 2. Оптимизация запросов к БД

#### Использование selectinload и joinedload
- **Место**: `app/services/report.py`
- **Оптимизация**: Загрузка связанных данных одним запросом вместо N+1 запросов
- **Примеры**:
  ```python
  query = query.options(selectinload(AuditReport.analysis_summary))
  query = query.options(selectinload(AuditReport.violations))
  query = query.options(joinedload(AuditReport.document))
  ```

#### Оптимизация подсчета записей
- Использование `func.count(Document.id)` вместо `func.count()`
- Использование индексов на ключевых полях

#### Connection Pooling
- **Настройки**: `app/core/database.py`
- **Параметры**:
  - `pool_size=10` - размер пула соединений
  - `max_overflow=20` - максимальное количество дополнительных соединений
  - `pool_recycle=3600` - переиспользование соединений каждый час
  - `pool_reset_on_return="commit"` - сброс транзакций при возврате в пул

### 3. Оптимизация работы с файлами

#### Асинхронная загрузка/чтение
- Использование `aiofiles` для асинхронной работы с файлами
- Неблокирующие операции чтения/записи

#### Оптимизация изображений
- **Модуль**: `app/utils/image_optimizer.py`
- **Функции**:
  - Изменение размера до максимума (1920x1080 по умолчанию)
  - Сжатие JPEG с качеством 85%
  - Конвертация RGBA в RGB для JPEG
- **Применение**: Автоматически при загрузке изображений
- **Экономия**: До 50-70% размера файла

### 4. Мониторинг производительности

#### Логирование медленных запросов
- **Middleware**: `app/middleware/query_logger.py`
- **Порог**: 1 секунда
- **Логирование**:
  - Путь запроса
  - Метод HTTP
  - Время выполнения
  - Статус код
  - IP адрес клиента
- **Заголовок ответа**: `X-Response-Time` с временем выполнения

### 5. Индексы базы данных

#### Существующие индексы
- `users.email` - уникальный индекс
- `users.id` - первичный ключ
- `documents.user_id` - индекс для фильтрации по пользователю
- `documents.file_hash` - индекс для поиска дубликатов
- `documents.status` - индекс для фильтрации по статусу
- `documents.created_at` - индекс для сортировки
- `audit_reports.document_id` - индекс для связи с документами
- `audit_reports.request_id` - уникальный индекс
- `audit_reports.status` - индекс для фильтрации
- `violations.audit_report_id` - индекс для связи с отчетами
- `violations.risk_level` - индекс для фильтрации по уровню риска
- `violations.code` - индекс для поиска по коду нарушения

## Рекомендации по дальнейшей оптимизации

### 1. Анализ медленных запросов

Для анализа медленных запросов в PostgreSQL:

```sql
-- Включение логирования медленных запросов
ALTER DATABASE medaudit_db SET log_min_duration_statement = 1000; -- 1 секунда

-- Просмотр медленных запросов
SELECT 
    query,
    calls,
    total_time,
    mean_time,
    max_time
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 20;
```

### 2. Мониторинг кеша

Проверка использования Redis кеша:

```bash
# Подключение к Redis
redis-cli

# Статистика использования памяти
INFO memory

# Просмотр ключей кеша
KEYS "reports:*"
KEYS "documents:*"
KEYS "pdf_report:*"

# Очистка кеша (осторожно!)
FLUSHDB
```

### 3. Оптимизация генерации PDF

- Использование кеша для готовых PDF (реализовано)
- Асинхронная генерация для больших отчетов (можно добавить очередь)
- Предварительная генерация популярных отчетов

### 4. Масштабирование

#### Горизонтальное масштабирование
- Несколько экземпляров backend через load balancer
- Несколько Celery workers для обработки задач
- Redis Cluster для распределенного кеша

#### Вертикальное масштабирование
- Увеличение `pool_size` и `max_overflow` для БД
- Увеличение памяти для Redis
- Увеличение количества Celery workers

### 5. Оптимизация миграций

Для больших таблиц используйте индексы с `CONCURRENTLY`:

```python
# В миграции Alembic
op.create_index(
    'idx_documents_user_status',
    'documents',
    ['user_id', 'status'],
    postgresql_concurrently=True
)
```

## Метрики производительности

### Целевые показатели

- **Время ответа API**: < 200ms для стандартных запросов
- **Время генерации PDF**: < 5 секунд для стандартных отчетов
- **Время обработки документа**: < 30 секунд (включая NLP)
- **Использование памяти**: < 2GB на экземпляр backend
- **Использование CPU**: < 70% в среднем

### Мониторинг

Рекомендуется использовать:
- **Prometheus** для метрик
- **Grafana** для визуализации
- **ELK Stack** для логов
- **Sentry** для отслеживания ошибок

## Тестирование производительности

### Нагрузочное тестирование

Используйте `tests/test_load.py` для базового тестирования:

```bash
pytest tests/test_load.py -v
```

### Профилирование

Для детального анализа используйте:

```python
# Добавьте в код для профилирования
import cProfile
import pstats

profiler = cProfile.Profile()
profiler.enable()
# Ваш код
profiler.disable()
stats = pstats.Stats(profiler)
stats.sort_stats('cumulative')
stats.print_stats(20)
```

## Заключение

Все основные оптимизации реализованы. Система готова к production использованию с возможностью дальнейшего масштабирования.


