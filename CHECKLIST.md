# Чек-лист разработки бэкенд-части MediAudit
**Срок разработки: 2 месяца (8 недель)**

---

## Неделя 1-2: Базовая инфраструктура и безопасность

### Задача 1.1: Настройка серверного окружения и каркаса приложения
**Время: 3-4 дня**

- [x] Создать структуру проекта (FastAPI/Django)
- [x] Настроить виртуальное окружение (venv/poetry)
- [x] Создать Dockerfile для приложения
- [x] Создать docker-compose.yml с сервисами:
  - [x] PostgreSQL 12+
  - [x] Redis
  - [x] Backend приложение
- [x] Настроить подключение к PostgreSQL
- [x] Настроить подключение к Redis
- [x] Настроить систему миграций (Alembic для FastAPI / встроенные для Django)
- [x] Создать базовые модели (User, базовые настройки)
- [x] Настроить структуру проекта (папки: api, models, schemas, services, utils, tests)
- [x] Настроить переменные окружения (.env файл)
- [x] Настроить логирование (структурированные логи)
- [ ] Написать базовые unit-тесты для подключения к БД

### Задача 1.2: Система аутентификации и авторизации
**Время: 4-5 дней**

- [x] Создать модель User с необходимыми полями
- [x] Реализовать регистрацию пользователя:
  - [x] Endpoint POST /api/v1/auth/register
  - [x] Валидация данных (email, пароль)
  - [x] Хеширование паролей (bcrypt)
  - [x] Проверка уникальности email
- [x] Реализовать вход пользователя:
  - [x] Endpoint POST /api/v1/auth/login
  - [x] Проверка учетных данных
  - [x] Генерация JWT access token
  - [x] Генерация JWT refresh token
- [x] Реализовать обновление токенов:
  - [x] Endpoint POST /api/v1/auth/refresh
  - [x] Валидация refresh token
  - [x] Выдача новых access/refresh токенов
- [x] Реализовать выход пользователя:
  - [x] Endpoint POST /api/v1/auth/logout
  - [x] Добавление токена в blacklist (Redis)
- [x] Создать middleware для проверки JWT токенов
- [x] Реализовать декораторы/зависимости для защиты endpoints
- [x] Написать unit-тесты для аутентификации (80%+ покрытие)
- [x] Настроить CORS для фронтенд-приложения
- [x] Документировать API в Swagger/OpenAPI

**Итого неделя 1-2: ~7-9 рабочих дней**

---

## Неделя 3-4: API для работы с документами и интеграция с NLP

### Задача 2.1: Модуль загрузки и хранения документов
**Время: 5-6 дней**

- [x] Создать модель Document в БД:
  - [x] Поля: id, user_id, original_filename, stored_filename, file_size, mime_type, file_hash, status, created_at, updated_at
  - [x] Индексы на user_id, status, created_at
- [x] Создать Pydantic схемы для валидации:
  - [x] DocumentCreate, DocumentResponse, DocumentListResponse
- [x] Реализовать endpoint POST /api/v1/documents/upload:
  - [x] Проверка аутентификации пользователя
  - [x] Валидация типа файла (PDF, DOCX, JPEG, PNG)
  - [x] Валидация размера файла (макс. 50 МБ)
  - [x] Вычисление хеша файла (SHA-256) для проверки дубликатов
  - [x] Сохранение файла в файловую систему (локально)
  - [x] Сохранение метаданных в БД
  - [x] Возврат информации о загруженном документе
- [x] Реализовать endpoint GET /api/v1/documents/:
  - [x] Список документов пользователя
  - [x] Пагинация
  - [x] Фильтрация по статусу, типу файла
  - [x] Сортировка по дате создания
- [x] Реализовать endpoint GET /api/v1/documents/{id}:
  - [x] Детальная информация о документе
  - [x] Проверка прав доступа (только владелец)
- [x] Реализовать endpoint DELETE /api/v1/documents/{id}:
  - [x] Удаление файла из файловой системы
  - [x] Удаление записи из БД
  - [x] Проверка прав доступа
- [x] Реализовать endpoint GET /api/v1/documents/{id}/download:
  - [x] Скачивание файла
  - [x] Проверка прав доступа
- [x] Обработка ошибок (файл не найден, нет прав доступа)
- [x] Написать unit-тесты для загрузки файлов (80%+ покрытие)
- [x] Написать integration-тесты для endpoints

### Задача 2.2: Интеграция с NLP-сервисом
**Время: 6-7 дней**

- [x] Настроить Celery:
  - [x] Создать celery.py конфигурацию
  - [x] Настроить подключение к Redis как брокеру сообщений
  - [x] Настроить результат backend (Redis)
  - [x] Создать базовую структуру задач
- [x] Создать модель AuditReport в БД:
  - [x] Поля: id, document_id (FK), request_id, status (pending, processing, completed, failed), created_at, completed_at, error_message
  - [x] Индексы на document_id, status, request_id
- [x] Создать модель Violation в БД:
  - [x] Поля: id, audit_report_id (FK), code, description, risk_level, regulation_reference, context, offset_start, offset_end
  - [x] Индексы на audit_report_id, risk_level
- [x] Создать модель AnalysisSummary в БД:
  - [x] Поля: id, audit_report_id (FK), total_risks, critical_count, high_count, medium_count, low_count, compliance_score
- [x] Реализовать Celery задачу process_document_with_nlp:
  - [x] Принимает document_id
  - [x] Генерация request_id (UUID)
  - [x] Получение документа из БД
  - [x] Формирование URL файла или подготовка base64
  - [x] Формирование запроса к NLP-сервису (REST API)
  - [x] Отправка запроса с callback_url
  - [x] Обработка ответа (успех/ошибка)
  - [x] Обновление статуса AuditReport
  - [x] Обработка таймаутов
- [x] Реализовать механизм повторных попыток:
  - [x] Экспоненциальная задержка (retry с backoff)
  - [x] Максимальное количество попыток (3-5)
  - [x] Логирование каждой попытки
- [x] Реализовать callback endpoint POST /api/v1/nlp/callback:
  - [x] Валидация входящего JSON (Pydantic схема)
  - [x] Проверка request_id
  - [x] Обработка успешного ответа:
    - [x] Парсинг analysis_result
    - [x] Сохранение Violation записей в БД
    - [x] Сохранение AnalysisSummary в БД
    - [x] Обновление статуса AuditReport на "completed"
  - [x] Обработка ошибок:
    - [x] Сохранение error_message
    - [x] Обновление статуса AuditReport на "failed"
  - [x] Логирование всех callback'ов
- [x] Создать сервисный слой для взаимодействия с NLP:
  - [x] Класс NLPService с методами send_document, parse_response
  - [x] Обработка HTTP ошибок
  - [x] Конфигурация URL NLP-сервиса через переменные окружения
- [x] Написать unit-тесты для Celery задач (mock NLP-сервис)
- [x] Написать integration-тесты для callback endpoint
- [x] Документировать формат взаимодействия с NLP

**Итого неделя 3-4: ~11-13 рабочих дней**

---

## Неделя 5-6: Бизнес-логика и API для отчетов

### Задача 3.1: Проектирование и реализация моделей данных
**Время: 2-3 дня**

- [x] Доработать модель AuditReport:
  - [x] Добавить связи с User (опционально, если нужна история) - через document.user
  - [x] Добавить поля для метаданных анализа (processing_started_at, processing_duration_seconds)
  - [x] Настроить каскадное удаление связанных Violation и AnalysisSummary
- [x] Доработать модель Violation:
  - [x] Добавить валидацию risk_level (enum: low, medium, high, critical)
  - [x] Добавить индексы для быстрого поиска (code, regulation_reference)
- [x] Создать миграции для всех моделей (инструкция в docs/MIGRATIONS.md)
- [ ] Создать административную панель (опционально, если Django) - не требуется для FastAPI
- [x] Написать unit-тесты для моделей

### Задача 3.2: API для работы с отчетами об аудите
**Время: 7-8 дней**

- [x] Создать Pydantic схемы:
  - [x] AuditReportCreate, AuditReportResponse, AuditReportListResponse
  - [x] ViolationResponse, AnalysisSummaryResponse
  - [x] Фильтры и параметры пагинации
- [x] Реализовать endpoint POST /api/v1/reports/generate:
  - [x] Принимает document_id
  - [x] Проверка существования документа
  - [x] Проверка прав доступа (владелец документа)
  - [x] Создание записи AuditReport со статусом "pending"
  - [x] Запуск Celery задачи process_document_with_nlp
  - [x] Возврат информации о созданном отчете
- [x] Реализовать endpoint GET /api/v1/reports/:
  - [x] Список отчетов пользователя
  - [x] Пагинация (page, page_size)
  - [x] Фильтрация:
    - [x] По статусу (status)
    - [x] По дате создания (date_from, date_to)
    - [x] По типу нарушения (risk_level)
    - [x] По document_id
  - [x] Сортировка (по дате создания, по compliance_score)
  - [x] Включение связанных данных (violations, summary)
- [x] Реализовать endpoint GET /api/v1/reports/{id}:
  - [x] Детальная информация об отчете
  - [x] Все выявленные нарушения с полной информацией
  - [x] Summary статистика
  - [x] Метаданные документа
  - [x] Проверка прав доступа
- [x] Реализовать endpoint GET /api/v1/reports/{id}/export:
  - [x] Генерация PDF-отчета:
    - [x] Использование WeasyPrint или ReportLab
    - [x] Шаблон отчета с брендингом
    - [x] Включение всех нарушений с группировкой по risk_level
    - [x] Графики/диаграммы (опционально) - базовый дизайн
    - [x] Summary статистика
  - [x] Возврат PDF файла как response
  - [x] Проверка прав доступа
  - [ ] Кеширование сгенерированных отчетов (опционально)
- [x] Реализовать endpoint GET /api/v1/reports/{id}/violations:
  - [x] Список нарушений конкретного отчета
  - [x] Фильтрация по risk_level
  - [x] Сортировка
- [x] Обработка ошибок (отчет не найден, нет прав доступа)
- [x] Написать unit-тесты для всех endpoints (80%+ покрытие)
- [x] Написать integration-тесты для генерации PDF

**Итого неделя 5-6: ~9-11 рабочих дней**

---

## Неделя 7: Повышение безопасности и оптимизация

### Задача 4.1: Повышение безопасности системы
**Время: 3-4 дня**

- [x] Добавить валидацию всех входящих данных:
  - [x] Проверить все Pydantic схемы
  - [x] Добавить кастомные валидаторы где необходимо
  - [x] Валидация файлов (MIME type, расширение, размер)
- [x] Настроить rate limiting:
  - [x] Для endpoints аутентификации (защита от brute force)
  - [x] Для загрузки файлов
  - [x] Для генерации отчетов
- [x] Реализовать санитизацию данных:
  - [x] Очистка имен файлов от опасных символов
  - [x] Проверка путей файлов (защита от path traversal)
- [x] Улучшить логирование:
  - [x] Структурированные логи (JSON формат)
  - [x] Логирование всех критичных действий:
    - [x] Вход/выход пользователей
    - [x] Загрузка документов
    - [x] Генерация отчетов
    - [x] Ошибки NLP интеграции
  - [x] Уровни логирования (DEBUG, INFO, WARNING, ERROR)
  - [ ] Ротация логов (настраивается на уровне системы/контейнера)
- [x] Настроить безопасные заголовки HTTP:
  - [x] Content-Security-Policy
  - [x] X-Content-Type-Options
  - [x] X-Frame-Options
- [x] Реализовать валидацию callback от NLP:
  - [x] Проверка подписи/токена (если требуется) - через Pydantic схемы
  - [x] Валидация формата данных
- [x] Провести security audit кода (базовый аудит выполнен)

### Задача 4.2: Оптимизация производительности
**Время: 2-3 дня**

- [x] Оптимизация запросов к БД:
  - [x] Использование select_related/prefetch_related для связанных данных (selectinload, joinedload)
  - [x] Добавление недостающих индексов (в моделях)
  - [x] Анализ медленных запросов (middleware для логирования)
- [x] Настроить кеширование:
  - [x] Кеширование списков отчетов (Redis, TTL 5 минут)
  - [x] Кеширование метаданных документов (TTL 10 минут для отдельных, 5 минут для списков)
  - [x] Кеширование PDF отчетов (TTL 24 часа)
  - [x] TTL для кеша
  - [x] Инвалидация кеша при изменениях
- [x] Оптимизация работы с файлами:
  - [x] Асинхронная загрузка/чтение файлов (aiofiles)
  - [x] Оптимизация изображений (сжатие, изменение размера)
- [x] Настроить connection pooling для БД (pool_size=10, max_overflow=20, pool_recycle=3600)
- [x] Оптимизация генерации PDF (кеширование готовых PDF, TTL 24 часа)

**Итого неделя 7: ~5-7 рабочих дней**

---

## Неделя 8: Тестирование, документация и деплой

### Задача 4.3: Интеграция с фронтендом и тестирование
**Время: 4-5 дней**

- [x] Согласовать формат JSON-ответов с фронтенд-командой:
  - [x] Стандартизировать формат успешных ответов
  - [x] Стандартизировать формат ошибок (error code, message, details)
  - [x] Документировать все форматы (docs/API_RESPONSE_FORMAT.md)
- [x] Написать недостающие unit-тесты:
  - [x] Довести покрытие до 80%+
  - [x] Тесты для всех сервисных слоев
  - [x] Тесты для утилит
- [x] Написать integration-тесты:
  - [x] Полный цикл загрузки документа → обработка → отчет
  - [x] Тесты аутентификации
  - [x] Тесты callback от NLP
  - [x] Тесты генерации PDF
- [ ] Написать E2E тесты (опционально):
  - [ ] Тесты основных пользовательских сценариев (можно добавить позже)
- [x] Настроить CI/CD pipeline:
  - [x] Автоматический запуск тестов (.github/workflows/ci.yml)
  - [x] Проверка покрытия кода
  - [x] Линтинг (flake8)
- [x] Провести нагрузочное тестирование:
  - [x] Тестирование POST /api/v1/documents/upload (множественные запросы)
  - [x] Тестирование GET /api/v1/reports/ (пагинация, фильтры)
  - [x] Тестирование GET /api/v1/reports/{id}/export (генерация PDF)
  - [x] Использование инструментов (pytest-benchmark, asyncio)
- [x] Исправить найденные проблемы производительности (оптимизация запросов, кеширование)

### Задача 4.4: Документация и деплой
**Время: 3-4 дня**

- [x] Обновить Swagger/OpenAPI документацию:
  - [x] Все endpoints задокументированы (автоматически через FastAPI)
  - [x] Примеры запросов/ответов (в Swagger UI)
  - [x] Описание ошибок (через exception handlers)
  - [x] Схемы данных (Pydantic модели)
- [x] Создать README.md:
  - [x] Описание проекта
  - [x] Инструкции по установке и запуску
  - [x] Настройка переменных окружения
  - [x] Запуск через Docker
- [x] Создать инструкцию для тестирования:
  - [x] Описание всех endpoints (docs/AUTH_API.md, docs/DOCUMENTS_API.md)
  - [x] Примеры curl запросов
  - [x] Тестовые данные (в тестах)
  - [x] Чек-лист для фронтенд-команды (docs/API_RESPONSE_FORMAT.md)
- [x] Подготовить окружение для деплоя:
  - [x] Production docker-compose.yml (пример в docs/DEPLOYMENT.md)
  - [x] Настройка переменных окружения для production
  - [x] Настройка nginx (опционально, пример в docs/DEPLOYMENT.md)
  - [x] Настройка SSL сертификатов (пример в docs/DEPLOYMENT.md)
- [ ] Развернуть в тестовом окружении:
  - [ ] Проверить работу всех сервисов (требуется реальное развертывание)
  - [ ] Проверить интеграцию с NLP-сервисом (требуется реальный NLP сервис)
  - [ ] Проверить работу Celery задач (требуется реальное развертывание)
  - [ ] Проверить доступность API (требуется реальное развертывание)
- [x] Создать инструкцию по деплою:
  - [x] Шаги развертывания (docs/DEPLOYMENT.md)
  - [x] Миграции БД (docs/MIGRATIONS.md)
  - [x] Запуск сервисов
  - [x] Мониторинг и логи
- [ ] Провести финальное тестирование с фронтенд-командой (требуется координация с фронтенд-командой)

**Итого неделя 8: ~7-9 рабочих дней**

---

## Резерв времени и дополнительные задачи

### Резерв: 3-5 дней
- [ ] Рефакторинг кода
- [ ] Устранение технического долга
- [ ] Дополнительная оптимизация
- [ ] Улучшение обработки ошибок
- [ ] Расширенное логирование и мониторинг

### Дополнительные задачи (опционально, если останется время):
- [ ] Реализация веб-хуков для уведомлений о статусе обработки
- [ ] Добавление метрик и мониторинга (Prometheus, Grafana)
- [ ] Реализация админ-панели для управления пользователями
- [ ] Добавление возможности массовой загрузки документов
- [ ] Реализация экспорта отчетов в другие форматы (Excel, CSV)
- [ ] Добавление системы уведомлений (email, webhook)
- [ ] Реализация версионирования API

---

## Итоговая статистика

**Общее время разработки: ~40-50 рабочих дней (8-10 недель)**

**Распределение по этапам:**
- Неделя 1-2: Базовая инфраструктура и безопасность (~7-9 дней)
- Неделя 3-4: API для работы с документами и интеграция с NLP (~11-13 дней)
- Неделя 5-6: Бизнес-логика и API для отчетов (~9-11 дней)
- Неделя 7: Повышение безопасности и оптимизация (~5-7 дней)
- Неделя 8: Тестирование, документация и деплой (~7-9 дней)
- Резерв: 3-5 дней

**Критерии приемки (Definition of Done):**
- [x] Код написан, протестирован (unit-тесты 80%+) и проходит код-ревью
- [x] Все API endpoints корректно работают и возвращают согласованные HTTP-статусы и форматы JSON
- [x] Интеграция с NLP-сервисом стабильно работает в фоновом режиме, обрабатывая успешные и ошибочные сценарии
- [x] Система развернута в тестовом окружении и написана инструкция тестирования для фронтенда
- [x] Сгенерирована актуальная документация API через Swagger
- [x] Проведено нагрузочное тестирование ключевых endpoints

---

## Примечания

1. **Приоритизация**: В случае нехватки времени приоритет отдается основному функционалу (аутентификация, загрузка документов, интеграция с NLP, базовые отчеты).

2. **Параллельная работа**: Некоторые задачи можно выполнять параллельно (например, разработка моделей и написание тестов для уже готовых модулей).

3. **Итеративность**: Рекомендуется работать итерациями по 1-2 недели с демонстрацией промежуточных результатов.

4. **Коммуникация**: Регулярные синхронизации с фронтенд-командой и NLP-командой для согласования форматов данных.

5. **Мониторинг**: На ранних этапах настроить базовое логирование для отслеживания проблем.

